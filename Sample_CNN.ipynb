{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import operating system \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set working directory\n",
    "data_dir = \"C:/Users/Emily/Documents/Fall_2020/ML_DS/Sample_Sentinel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Idrisi32.lo2',\n",
       " 'Idrisi32.log',\n",
       " 'L1C_T19TBG_A025748_20200527T154252.rst.aux.xml',\n",
       " 'L1C_T19TBG_A025748_20200527T154252.tif',\n",
       " 'Sample_Bing_1.png',\n",
       " 'Sample_Bing_2.png',\n",
       " 'Split1.png',\n",
       " 'Split_1_Samples',\n",
       " 'Split_Imagery.ipynb',\n",
       " 'Testing_Data',\n",
       " 'Training_Data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List folders in the working directory\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set testing and training data folders to different variables\n",
    "test_path = data_dir + '/Testing_Data/'\n",
    "train_path = data_dir + '/Training_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Emily/Documents/Fall_2020/ML_DS/Sample_Sentinel/Testing_Data/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that is worked by calling the path name\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Split1_54_06.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the first training image within the \"Solar\" folder. The solar folder shows training images of the solar field\n",
    "os.listdir(train_path + 'Solar')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the first training image to a variable\n",
    "solar_cell = (train_path + 'Solar/' + 'Split1_54_06.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import matplotlib (library for plotting and displaying data)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x207409d5ec8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show the first image in the training 'Solar' folder\n",
    "plt.imshow(imread(solar_cell), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41960785"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if image is normalized or if brightness ranges from 0-255. Normalize if not. \n",
    "imread(solar_cell).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Image Data Generator from Tensorflow. This function expands our training dataset by flipping and rotating images. Should produce a more robust model.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "image_gen = ImageDataGenerator(rotation_range=180, width_shift_range = 0.1, height_shift_range= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the image generator to the training data\n",
    "#image_gen.flow_from_directory(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tools to build model. \n",
    "#I am using a Sequential model which allows me to add layers in a custom order\n",
    "from tensorflow.keras.models import Sequential\n",
    "#Import specific types of layers I will use 1. Dense fully connected layer, Convlutional 2d layer, Max Pooling 2d Layer, and Flattening layer\n",
    "#2D means we're looking at a greyscale image. 3d would be RGB\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, AveragePooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate model object\n",
    "model = Sequential()\n",
    "'''\n",
    "Convolutional layer\n",
    "\n",
    "filer = the number of output filters in the convolution\n",
    "kernel_size = specifying the height and width of the 2D convolution window\n",
    "strides = specifying the strides of the convolution along the height and width\n",
    "activation function = activation function to use\n",
    "\n",
    "Pool layer \n",
    "\n",
    "pool_size = window size over which to take the maximum or average\n",
    "padding =  \"same\" adds padding such that if the stride is 1, the output shape is the same as input shape\n",
    "\n",
    "Flatten - turns the 2D image data into 1D vectors\n",
    "\n",
    "Dense layer\n",
    "Fully connected layer - for example, what TerrSet uses in MLP. \n",
    "In this case, you specify the number of nodes and the activation function.\n",
    "\n",
    "'''\n",
    "\n",
    "model.add(Conv2D(filters = 20, kernel_size = (9,9), strides = 2, activation = 'relu'))\n",
    "model.add(AveragePooling2D(pool_size =(3,3), padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(filters = 10, kernel_size = (6,6), strides = 1, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(2,2), padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(filters = 10, kernel_size = (16,16), strides = 3, activation = 'relu'))\n",
    "model.add(AveragePooling2D(pool_size =(4,4), padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "'''\n",
    "This line compiles the whole model.\n",
    "\n",
    "loss = The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n",
    "optimizer = A function for reducing learning and momentum parameters as it trains\n",
    "metrics = A metric is a function that is used to judge the performance of your model. Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model.\n",
    "'''\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer ='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import EarlyStopping object so we limit overfitting\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Early stop\n",
    "\n",
    "monitor = Quantity to be monitored. Val_loss cost function for your cross-validation (testing?) data\n",
    "patience = Number of epochs with no improvement after which training will be stopped\n",
    "\"\"\"\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Apply image_generator to training data\n",
    "train_image_gen = image_gen.flow_from_directory(train_path, color_mode='grayscale', shuffle = False, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Apply image_generator to testing data\n",
    "test_image_gen = image_gen.flow_from_directory(test_path, color_mode='grayscale', batch_size = batch_size, shuffle = False, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 19 steps\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.9053 - accuracy: 0.5000 - val_loss: 11.3035 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.4438 - accuracy: 0.5000 - val_loss: 4.8835 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.5013 - accuracy: 0.5000 - val_loss: 1.1755 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0884 - accuracy: 0.5000 - val_loss: 0.6843 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6839 - accuracy: 0.5357 - val_loss: 0.6779 - val_accuracy: 0.5135\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6749 - accuracy: 0.5000 - val_loss: 0.7199 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7213 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run the model. We use the generated image dataset to train for a maximum of 20 epochs. \n",
    "The generated testing data is used to measure the loss. It will stop based on the EarlyStopping parameters.\n",
    "'''\n",
    "results = model.fit(train_image_gen, epochs=20, validation_data=test_image_gen, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the model outputs for the testing data\n",
    "pred = model.predict(test_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a threshold for what is solar or not. In this case, anything with a probablity of >40% is considered solar. \n",
    "predictions = pred > 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 26]\n",
      " [ 4 33]]\n"
     ]
    }
   ],
   "source": [
    "#Print classification results. Top left is (Not Solar, Not Solar) and the bottom right is (Solar, Solar)\n",
    "print (confusion_matrix(test_image_gen.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten data so I can create a dataframe\n",
    "#Import numpy\n",
    "import numpy as np\n",
    "\n",
    "#Retrieve file names an flatten to 1D array\n",
    "names = test_image_gen.filenames\n",
    "names = np.array(names)\n",
    "names = np.ndarray.flatten(names)\n",
    "\n",
    "#Retrieve True Classes and flatten to 1D array\n",
    "classes = test_image_gen.classes\n",
    "classes = np.array(classes)\n",
    "classes = np.ndarray.flatten(classes)\n",
    "\n",
    "#Retreive predictions\n",
    "predictions = np.array(predictions)\n",
    "predictions = np.ndarray.flatten(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     FileName  Classes  Predictions\n",
      "0   NotSolar\\Split1_01_02.png        0         True\n",
      "1   NotSolar\\Split1_01_08.png        0         True\n",
      "2   NotSolar\\Split1_01_13.png        0         True\n",
      "3   NotSolar\\Split1_01_16.png        0         True\n",
      "4   NotSolar\\Split1_01_20.png        0         True\n",
      "..                        ...      ...          ...\n",
      "69     Solar\\Split1_63_11.png        1         True\n",
      "70     Solar\\Split1_64_09.png        1         True\n",
      "71     Solar\\Split1_64_10.png        1         True\n",
      "72     Solar\\Split1_65_09.png        1         True\n",
      "73     Solar\\Split1_65_10.png        1         True\n",
      "\n",
      "[74 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create dictionary of column names and the data above\n",
    "d = {'FileName': names, 'Classes': classes, 'Predictions': predictions}\n",
    "\n",
    "#Convert dictionary into a dataframe\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data=d)\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
